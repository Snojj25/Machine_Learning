{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "horse2zebra.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1149NvfoiKXMbcKQppoOH7DWCTlEJX9in",
      "authorship_tag": "ABX9TyMe35kOOIvFJJvQkuxwx9jc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Snojj25/Machine_Learning/blob/main/horse2zebra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DF12Nwj8I5g"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1HJcVVrSrWI"
      },
      "source": [
        "zip_path = \"/content/drive/MyDrive/Datasets/horse2zebra.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwky_jtXTLa_"
      },
      "source": [
        "import os\r\n",
        "import zipfile\r\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S83nzWeNTODp"
      },
      "source": [
        "shutil.rmtree('/tmp')\r\n",
        "\r\n",
        "local_zip = zip_path\r\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\r\n",
        "zip_ref.extractall('/tmp/horse2zebra')\r\n",
        "\r\n",
        "parent_dir = \"/tmp/horse2zebra/horse2zebra/\"\r\n",
        "\r\n",
        "train_path = os.path.join(parent_dir, \"train\")\r\n",
        "test_path = os.path.join(parent_dir, \"test\")\r\n",
        "\r\n",
        "os.mkdir(train_path) \r\n",
        "os.mkdir(test_path) \r\n",
        "\r\n",
        "os.mkdir(os.path.join(train_path, \"horse\"))\r\n",
        "os.mkdir(os.path.join(train_path, \"zebra\"))\r\n",
        "os.mkdir(os.path.join(test_path, \"horse\"))\r\n",
        "os.mkdir(os.path.join(test_path, \"zebra\"))\r\n",
        "\r\n",
        "train_H = \"/tmp/horse2zebra/horse2zebra/trainA\"\r\n",
        "train_Z = \"/tmp/horse2zebra/horse2zebra/trainB\"\r\n",
        "\r\n",
        "test_H = \"/tmp/horse2zebra/horse2zebra/testA\"\r\n",
        "test_Z = \"/tmp/horse2zebra/horse2zebra/testB\"\r\n",
        "\r\n",
        "train_dir_H = \"/tmp/horse2zebra/horse2zebra/train/horse\"\r\n",
        "train_dir_Z = \"/tmp/horse2zebra/horse2zebra/train/zebra\"\r\n",
        "test_dir_H = \"/tmp/horse2zebra/horse2zebra/test/horse\"\r\n",
        "test_dir_Z = \"/tmp/horse2zebra/horse2zebra/test/zebra\"\r\n",
        "\r\n",
        "_ = shutil.move(train_H, train_dir_H)  \r\n",
        "_ = shutil.move(train_Z, train_dir_Z)  \r\n",
        "_ = shutil.move(test_H, test_dir_H)  \r\n",
        "_ = shutil.move(test_Z, test_dir_Z)   \r\n",
        "\r\n",
        "zip_ref.close()\r\n",
        "\r\n",
        "del parent_dir, train_H, train_Z, test_H, test_Z, train_path, test_path, _"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecWuQN47D3hl"
      },
      "source": [
        "train_horse_path = os.path.join(train_dir_H, \"trainA\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0uKh019TPRo"
      },
      "source": [
        "# Plotting the image ======================================\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "image = Image.open(os.path.join(train_horse_path, \"n02381460_1025.jpg\"))\r\n",
        "# summarize some details about the image\r\n",
        "print(image.format)\r\n",
        "print(image.size)\r\n",
        "print(image.mode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CPBCWUHTPUh"
      },
      "source": [
        "%matplotlib inline\r\n",
        "\r\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZt1xPlxTPW4"
      },
      "source": [
        "# ===== Generators =============================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToLkMZ_VTPZq"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRCgb4HBVOS_"
      },
      "source": [
        "def get_train_generators(batch_size):\r\n",
        "  train_datagen = ImageDataGenerator(rescale=1. /255,\r\n",
        "                                    width_shift_range=0.2,\r\n",
        "                                    height_shift_range=0.2,\r\n",
        "                                    rotation_range=25,\r\n",
        "                                    zoom_range=0.2,\r\n",
        "                                    horizontal_flip=True,\r\n",
        "                                    fill_mode='reflect')\r\n",
        "\r\n",
        "\r\n",
        "  train_datagen_H = train_datagen.flow_from_directory(train_dir_H,\r\n",
        "                                                      batch_size=batch_size,\r\n",
        "                                                      target_size=(256, 256),\r\n",
        "                                                      class_mode=None) \r\n",
        "   \r\n",
        "  train_datagen_Z = train_datagen.flow_from_directory(train_dir_Z,  \r\n",
        "                                                      batch_size=batch_size,\r\n",
        "                                                      target_size=(256, 256),\r\n",
        "                                                      class_mode=None)  \r\n",
        "  \r\n",
        "  return train_datagen_H, train_datagen_Z\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def get_test_generators(batch_size):\r\n",
        "\r\n",
        "  test_datagen = ImageDataGenerator(rescale=1. /255)\r\n",
        "\r\n",
        "    \r\n",
        "  test_datagen_H =  test_datagen.flow_from_directory(test_dir_H,\r\n",
        "                                                     batch_size=batch_size,\r\n",
        "                                                     target_size=(256, 256),\r\n",
        "                                                     class_mode=None)\r\n",
        "    \r\n",
        "  test_datagen_Z =  test_datagen.flow_from_directory(test_dir_Z,\r\n",
        "                                                     batch_size=batch_size,\r\n",
        "                                                     target_size=(256, 256),\r\n",
        "                                                     class_mode=None)\r\n",
        "  \r\n",
        "  return test_datagen_H, test_datagen_Z\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLIT3raVeBo1"
      },
      "source": [
        "# Defining the model components ====================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Hh9nfpiqdj"
      },
      "source": [
        "!pip install -U tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkOSyTjzfRaO"
      },
      "source": [
        "from tensorflow.keras.layers import Layer \r\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, Conv2DTranspose, ReLU, LeakyReLU, Activation\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras import regularizers \r\n",
        "# from tensorflow.keras.activations import tanh\r\n",
        "\r\n",
        "from tensorflow_addons.layers import InstanceNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCd3NDEafeM8"
      },
      "source": [
        "class ResidualBlock(Model):\r\n",
        "\r\n",
        "  '''\r\n",
        "    ResidualBlock Class:\r\n",
        "    Performs two convolutions and an instance normalization, the input is added\r\n",
        "    to this output to form the residual block output.\r\n",
        "    Values:\r\n",
        "        hidden_channels: the number of channels to expect from a given input\r\n",
        "    '''\r\n",
        "\r\n",
        "  def __init__(self, hidden_channels=256, **kwargs):\r\n",
        "    super(ResidualBlock, self).__init__(**kwargs)\r\n",
        "    self.conv1 = Conv2D(hidden_channels, kernel_size=3, padding=\"same\")\r\n",
        "    self.conv2 = Conv2D(hidden_channels, kernel_size=3, padding=\"same\")\r\n",
        "    self.instanceNorm = InstanceNormalization()\r\n",
        "    self.activation = ReLU()\r\n",
        "\r\n",
        "  # def forward(self, input):\r\n",
        "  def call(self, inputs):\r\n",
        "        '''\r\n",
        "        Function for completing a forward pass of ResidualBlock: \r\n",
        "        Given an image tensor, completes a residual block and returns the transformed tensor.\r\n",
        "        Parameters:\r\n",
        "            x: image tensor of shape (batch size, channels, height, width)\r\n",
        "        '''\r\n",
        "        original_x = inputs\r\n",
        "        # x = tf.pad(input, [[0, 0], [1, 1], [1, 1], [0, 0]], \"CONSTANT\")\r\n",
        "        x = self.conv1(inputs)\r\n",
        "        x = self.instanceNorm(x)\r\n",
        "        x = self.activation(x)\r\n",
        "        # x = tf.pad(x, [[0, 0], [1, 1], [1, 1], [0, 0]], \"CONSTANT\")\r\n",
        "        x = self.conv2(x)\r\n",
        "        x = self.instanceNorm(x)\r\n",
        "        return original_x + x\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOke0DXFcG_-"
      },
      "source": [
        "class ContractingBlock(Model):\r\n",
        "  '''\r\n",
        "    ContractingBlock Class\r\n",
        "    Performs a convolution followed by a max pool operation and an optional instance norm.\r\n",
        "    Values:\r\n",
        "        hidden_channels: the number of channels to return from a given input\r\n",
        "    '''\r\n",
        "  \r\n",
        "  def __init__(self, hidden_channels, kernel_size=3, stride=2, use_bn=True, activation=\"relu\", **kwargs):\r\n",
        "    super(ContractingBlock, self).__init__(**kwargs)\r\n",
        "    self.conv1 = Conv2D(filters=hidden_channels, kernel_size=kernel_size, strides=(stride,stride))\r\n",
        "    self.relu = ReLU() if activation ==\"relu\" else LeakyReLU()\r\n",
        "    if use_bn:\r\n",
        "      self.instanceNorm = InstanceNormalization()\r\n",
        "    self.use_bn = use_bn\r\n",
        "\r\n",
        "  def call(self, inputs):\r\n",
        "    '''\r\n",
        "      Function for completing a forward pass of ContractingBlock: \r\n",
        "      Given an image tensor, completes a contracting block and returns the transformed tensor.\r\n",
        "      Parameters:\r\n",
        "          x: image tensor of shape (batch size, channels, height, width)\r\n",
        "    '''\r\n",
        "    x = self.conv1(inputs)\r\n",
        "    if self.use_bn:\r\n",
        "      x = self.instanceNorm(x)\r\n",
        "    x = self.relu(x)\r\n",
        "    return x\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmSFDvlUZvdx"
      },
      "source": [
        "class ExpandingBlock(Model):\r\n",
        "\r\n",
        "  def __init__(self, hidden_channels=64, kernel_size=3, stride=2, use_bn=True, activation=\"relu\", **kwargs):\r\n",
        "    super(ExpandingBlock, self).__init__(**kwargs)\r\n",
        "    self.convT1 = Conv2DTranspose(filters=hidden_channels, kernel_size=kernel_size, strides=(stride, stride), )\r\n",
        "    self.activation = ReLU() if activation==\"relu\" else LeakyReLU()\r\n",
        "    if use_bn:\r\n",
        "      self.instanceNorm = InstanceNormalization()\r\n",
        "    self.use_bn = use_bn\r\n",
        "\r\n",
        "  def call(self, inputs):\r\n",
        "\r\n",
        "    x = self.convT1(inputs)\r\n",
        "    if self.use_bn:\r\n",
        "      x = self.instanceNorm(x)\r\n",
        "    x = self.activation(x)\r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAH_Ke73cmQn"
      },
      "source": [
        "class FeatureMapLayer(Model):\r\n",
        "\r\n",
        "  def __init__(self, out_channels, **kwargs):\r\n",
        "    super(FeatureMapLayer, self).__init__(**kwargs)\r\n",
        "    self.conv = Conv2D(filters=out_channels, kernel_size=7, strides=(1,1), padding=\"same\")\r\n",
        "\r\n",
        "  def call(self, inputs):\r\n",
        "    x = self.conv(inputs)\r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PW-lZFCcHFZ"
      },
      "source": [
        "# Defining the Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weVdfye-eDuU"
      },
      "source": [
        "class Generator(Model):\r\n",
        "  \r\n",
        "  def __init__(self, hidden_channels=64, **kwargs):\r\n",
        "    super(Generator, self).__init__(**kwargs)\r\n",
        "    self.up_feature = FeatureMapLayer(out_channels= hidden_channels, name=\"up_feature\")\r\n",
        "    self.contracting1 = ContractingBlock(hidden_channels= 2*hidden_channels, name=\"contracting1\")\r\n",
        "    self.contracting2 = ContractingBlock(hidden_channels= 4*hidden_channels, name=\"contracting2\")\r\n",
        "    self.res1 = ResidualBlock(hidden_channels= 4*hidden_channels, name=\"residual1\")\r\n",
        "    self.res2 = ResidualBlock(hidden_channels= 4*hidden_channels, name=\"residual2\")\r\n",
        "    self.res3 = ResidualBlock(hidden_channels= 4*hidden_channels, name=\"residual3\")\r\n",
        "    self.res4 = ResidualBlock(hidden_channels= 4*hidden_channels, name=\"residual4\")\r\n",
        "    self.res5 = ResidualBlock(hidden_channels= 4*hidden_channels, name=\"residual5\")\r\n",
        "    self.res6 = ResidualBlock(hidden_channels= 4*hidden_channels, name=\"residual6\")\r\n",
        "    self.expanding1 = ExpandingBlock(hidden_channels= 2*hidden_channels, name=\"expanding1\")\r\n",
        "    self.expanding2 = ExpandingBlock(hidden_channels= hidden_channels, kernel_size=4, name=\"expanding2\")\r\n",
        "    self.down_feature = FeatureMapLayer(out_channels= 3, name=\"down_feature\")\r\n",
        "    self.tanh = Activation(\"tanh\")\r\n",
        "    \r\n",
        "  def call(self, inputs):\r\n",
        "    '''\r\n",
        "    Propagates the images through the contacting layers,\r\n",
        "    than the residual layers and finally through the expanding layers,\r\n",
        "    to return the output image.\r\n",
        "    '''\r\n",
        "    x1 = self.up_feature(inputs)\r\n",
        "    x2 = self.contracting1(x1)\r\n",
        "    x3 = self.contracting2(x2)\r\n",
        "    x4 = self.res1(x3)\r\n",
        "    x5 = self.res1(x4)\r\n",
        "    x6 = self.res1(x5)\r\n",
        "    x7 = self.res1(x6)\r\n",
        "    x8 = self.res1(x7)\r\n",
        "    x9 = self.res1(x8)\r\n",
        "    x10 = self.expanding1(x9)\r\n",
        "    x11 = self.expanding2(x10)\r\n",
        "    x12 = self.down_feature(x11)\r\n",
        "    out = self.tanh(x12)\r\n",
        "    return out\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1X5XZ8JATFv"
      },
      "source": [
        "# gen = Generator()\r\n",
        "\r\n",
        "# gen.build((32, 256,256,3))\r\n",
        "# gen.get_layer(\"residual2\").build((32,256,256,256))\r\n",
        "# gen.get_layer(\"residual3\").build((32,256,256,256))\r\n",
        "# gen.get_layer(\"residual4\").build((32,256,256,256))\r\n",
        "# gen.get_layer(\"residual5\").build((32,256,256,256))\r\n",
        "# gen.get_layer(\"residual6\").build((32,256,256,256))\r\n",
        "# gen.summary()\r\n",
        "\r\n",
        "# inp = tf.random.uniform([1,256,256,3], dtype=tf.dtypes.float32)\r\n",
        "# out = gen(inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_kmpg0_aWyb"
      },
      "source": [
        "\r\n",
        "class Discriminator(Model):\r\n",
        "\r\n",
        "  '''\r\n",
        "    Discriminator Class\r\n",
        "    Structured like the contracting path of the U-Net, the discriminator will\r\n",
        "    output a matrix of values classifying corresponding portions of the image as real or fake. \r\n",
        "    Parameters:\r\n",
        "        hidden_channels: the initial number of discriminator convolutional filters\r\n",
        "    '''\r\n",
        "\r\n",
        "  def __init__(self, hidden_channels=64):\r\n",
        "    super(Discriminator, self).__init__()\r\n",
        "\r\n",
        "    self.up_feature = FeatureMapLayer(64)\r\n",
        "    self.contracting1 = ContractingBlock(hidden_channels=2*hidden_channels, kernel_size=4, activation=\"LReLU\")\r\n",
        "    self.contracting2 = ContractingBlock(hidden_channels=4*hidden_channels, kernel_size=4, activation=\"LReLU\")\r\n",
        "    self.contracting3 = ContractingBlock(hidden_channels=8*hidden_channels, kernel_size=4, activation=\"LReLU\")\r\n",
        "    self.final = Conv2D(filters=1, kernel_size=1)\r\n",
        "    self.sigmoid = Activation(\"sigmoid\")\r\n",
        "\r\n",
        "  def call(self, inputs):\r\n",
        "    \r\n",
        "    x = self.up_feature(inputs)\r\n",
        "    x = self.contracting1(x)\r\n",
        "    x = self.contracting2(x)\r\n",
        "    x = self.contracting3(x)\r\n",
        "    x = self.final(x)\r\n",
        "    out = self.sigmoid(x)\r\n",
        "    return out\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79Au7ImPCyCr"
      },
      "source": [
        "# disc = Discriminator()\r\n",
        "\r\n",
        "# disc.build((32,256,256,3))\r\n",
        "\r\n",
        "# disc.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZfF-yJDgCNL"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fub84a-pSWMy"
      },
      "source": [
        "# test1 = tf.random.uniform([1, 30, 30])\r\n",
        "# test2 = tf.random.uniform([1, 30, 30])\r\n",
        "\r\n",
        "# loss = MeanSquaredError(reduction=tf.keras.losses.Reduction.AUTO)\r\n",
        "# print(loss(test1,test2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTIZAn9_jXDx"
      },
      "source": [
        "def get_disc_loss(real_X, fake_X, disc_X, adv_critereon):\r\n",
        "  '''\r\n",
        "    Return the loss of the discriminator given inputs.\r\n",
        "    Parameters:\r\n",
        "        real_X: the real images from pile X\r\n",
        "        fake_X: the generated images of class X\r\n",
        "        disc_X: the discriminator for class X; takes images and returns real/fake class X\r\n",
        "            prediction matrices\r\n",
        "        adv_criterion: the adversarial loss function; takes the discriminator \r\n",
        "            predictions and the target labels and returns a adversarial \r\n",
        "            loss (which you aim to minimize)\r\n",
        "    '''\r\n",
        "\r\n",
        "  real_pred = disc_X(real_X)\r\n",
        "  fake_pred = disc_X(fake_X)\r\n",
        "  real_loss = adv_critereon(real_pred, tf.ones_like(real_pred))\r\n",
        "  fake_loss = adv_critereon(fake_pred, tf.zeros_like(fake_pred))\r\n",
        "  disc_loss = (real_loss + fake_loss)/2\r\n",
        "  return disc_loss\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zcYx5vjlima"
      },
      "source": [
        "def get_gen_adversarial_loss(real_X, disc_Y, gen_XY, adv_criterion):\r\n",
        "    '''\r\n",
        "    Return the adversarial loss of the generator given inputs\r\n",
        "    (and the generated images for testing purposes).\r\n",
        "    Parameters:\r\n",
        "        real_X: the real images from pile X\r\n",
        "        disc_Y: the discriminator for class Y; takes images and returns real/fake class Y\r\n",
        "            prediction matrices\r\n",
        "        gen_XY: the generator for class X to Y; takes images and returns the images \r\n",
        "            transformed to class Y\r\n",
        "        adv_criterion: the adversarial loss function; takes the discriminator \r\n",
        "                  predictions and the target labels and returns a adversarial \r\n",
        "                  loss (which you aim to minimize)\r\n",
        "    '''\r\n",
        "\r\n",
        "    fake_Y = gen_XY(real_X)\r\n",
        "    # fake_Y_pred = tf.squeeze(disc_Y(fake_Y))\r\n",
        "    fake_Y_pred = disc_Y(fake_Y)\r\n",
        "    generator_loss = adv_criterion(fake_Y_pred, tf.ones_like(fake_Y_pred))\r\n",
        "    return generator_loss, fake_Y\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqSsZsMg4dcm"
      },
      "source": [
        "def get_identity_loss(real_X, gen_YX, identity_criterion):\r\n",
        "    '''\r\n",
        "    Return the identity loss of the generator given inputs\r\n",
        "    (and the generated images for testing purposes).\r\n",
        "    Parameters:\r\n",
        "        real_X: the real images from pile X\r\n",
        "        gen_YX: the generator for class Y to X; takes images and returns the images \r\n",
        "            transformed to class X\r\n",
        "        identity_criterion: the identity loss function; takes the real images from X and\r\n",
        "                        those images put through a Y->X generator and returns the identity \r\n",
        "                        loss (which you aim to minimize)\r\n",
        "    '''\r\n",
        "\r\n",
        "    identity_X = gen_YX(real_X)\r\n",
        "    identity_loss = identity_criterion(identity_X, real_X)\r\n",
        "    return identity_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vtIWnDq5MXd"
      },
      "source": [
        "def get_cycle_consistancy_loss(real_X, fake_Y, gen_YX, cycle_critereon):\r\n",
        "    '''\r\n",
        "    Return the cycle consistency loss of the generator given inputs\r\n",
        "    (and the generated images for testing purposes).\r\n",
        "    Parameters:\r\n",
        "        real_X: the real images from pile X\r\n",
        "        fake_Y: the generated images of class Y\r\n",
        "        gen_YX: the generator for class Y to X; takes images and returns the images \r\n",
        "            transformed to class X\r\n",
        "        cycle_criterion: the cycle consistency loss function; takes the real images from X and\r\n",
        "                        those images put through a X->Y generator and then Y->X generator\r\n",
        "                        and returns the cycle consistency loss (which you aim to minimize)\r\n",
        "    '''\r\n",
        "    cycle_X = gen_YX(fake_Y)\r\n",
        "    cycle_loss = cycle_critereon(cycle_X, real_X)\r\n",
        "    return cycle_loss\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1o4OxCqjvf5"
      },
      "source": [
        "def get_generator_loss(real_A, real_B, gen_AB, gen_BA, disc_A, disc_B,\r\n",
        "                       adv_critereon, identity_critereon, cycle_critereon,\r\n",
        "                       lambda_identity=0.1, lambda_cycle=10):\r\n",
        "  '''\r\n",
        "  Return the loss of the generator given inputs.\r\n",
        "    Parameters:\r\n",
        "        real_A: the real images from pile A\r\n",
        "        real_B: the real images from pile B\r\n",
        "        gen_AB: the generator for class A to B; takes images and returns the images \r\n",
        "            transformed to class B\r\n",
        "        gen_BA: the generator for class B to A; takes images and returns the images \r\n",
        "            transformed to class A\r\n",
        "        disc_A: the discriminator for class A; takes images and returns real/fake class A\r\n",
        "            prediction matrices\r\n",
        "        disc_B: the discriminator for class B; takes images and returns real/fake class B\r\n",
        "            prediction matrices\r\n",
        "        adv_criterion: the adversarial loss function; takes the discriminator \r\n",
        "            predictions and the true labels and returns a adversarial \r\n",
        "            loss (which you aim to minimize)\r\n",
        "        identity_criterion: the reconstruction loss function used for identity loss\r\n",
        "            and cycle consistency loss; takes two sets of images and returns\r\n",
        "            their pixel differences (which you aim to minimize)\r\n",
        "        cycle_criterion: the cycle consistency loss function; takes the real images from X and\r\n",
        "            those images put through a X->Y generator and then Y->X generator\r\n",
        "            and returns the cycle consistency loss (which you aim to minimize).\r\n",
        "            Note that in practice, cycle_criterion == identity_criterion == L1 loss\r\n",
        "        lambda_identity: the weight of the identity loss\r\n",
        "        lambda_cycle: the weight of the cycle-consistency loss\r\n",
        "    '''\r\n",
        "\r\n",
        "  adv_loss_A, fake_B = get_gen_adversarial_loss(real_X=real_A, disc_Y=disc_B, gen_XY=gen_AB, adv_criterion=adv_critereon)\r\n",
        "  adv_loss_B, fake_A = get_gen_adversarial_loss(real_X=real_B, disc_Y=disc_A, gen_XY=gen_BA, adv_criterion=adv_critereon)\r\n",
        "\r\n",
        "  identity_loss_A = get_identity_loss(real_X=real_A, gen_YX=gen_BA, identity_criterion=identity_critereon)\r\n",
        "  identity_loss_B = get_identity_loss(real_X=real_B, gen_YX=gen_BA, identity_criterion=identity_critereon)\r\n",
        "\r\n",
        "  cycle_loss_A = get_cycle_consistancy_loss(real_X=real_A, fake_Y=fake_B, gen_YX=gen_BA, cycle_critereon=cycle_critereon)\r\n",
        "  cycle_loss_B = get_cycle_consistancy_loss(real_X=real_B, fake_Y=fake_A, gen_YX=gen_AB, cycle_critereon=cycle_critereon)\r\n",
        "\r\n",
        "  adversarial_loss = tf.math.add(adv_loss_A, adv_loss_B)\r\n",
        "  identity_loss = tf.math.add(identity_loss_A, identity_loss_B)  \r\n",
        "  cycle_consistancy_loss = tf.math.add(cycle_loss_A, cycle_loss_B) \r\n",
        "\r\n",
        "  generator_loss = adversarial_loss + lambda_identity * identity_loss + lambda_cycle * cycle_consistancy_loss\r\n",
        "  return generator_loss, fake_A, fake_B\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL3kykVMtMZ4"
      },
      "source": [
        "# Training the networks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1crDjiZBACIo"
      },
      "source": [
        "batch_size = 1\r\n",
        "gen_lr = 0.0002\r\n",
        "disc_lr = 0.00001\r\n",
        "\r\n",
        "adv_critereon = MeanSquaredError()\r\n",
        "identity_critereon = MeanAbsoluteError()\r\n",
        "cycle_critereon = MeanAbsoluteError()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm6nVeKbeXSL"
      },
      "source": [
        "# Generator Models and optimizer\r\n",
        "gen_HZ = Generator()\r\n",
        "gen_ZH = Generator()\r\n",
        "gen_optim = Adam(learning_rate=gen_lr, beta_1=0.5, name=\"gen_optim\")\r\n",
        "\r\n",
        "# Check for saved generator model weights \r\n",
        "if os.path.exists(\"/content/drive/MyDrive/Models/horse2zebra/gen_HZ.index\"):\r\n",
        "  print(\"loaded weigths for gen_HZ\")\r\n",
        "  gen_HZ.load_weights(\"/content/drive/MyDrive/Models/horse2zebra/gen_HZ\")\r\n",
        "\r\n",
        "if os.path.exists(\"/content/drive/MyDrive/Models/horse2zebra/gen_ZH.index\"):\r\n",
        "  print(\"loaded weigths for gen_ZH\")\r\n",
        "  gen_ZH.load_weights(\"/content/drive/MyDrive/Models/horse2zebra/gen_ZH\")\r\n",
        "\r\n",
        "\r\n",
        "# Generator models and optimizers\r\n",
        "disc_H = Discriminator()\r\n",
        "disc_Z = Discriminator()\r\n",
        "disc_optim = Adam(learning_rate=disc_lr, beta_1=0.5, name=\"disc_optim\")\r\n",
        "\r\n",
        "# Check for saved generator model weights \r\n",
        "if os.path.exists(\"/content/drive/MyDrive/Models/horse2zebra/disc_H.index\"):\r\n",
        "  print(\"loaded weigths for disc_H\")\r\n",
        "  disc_H.load_weights(\"/content/drive/MyDrive/Models/horse2zebra/disc_H\")\r\n",
        "\r\n",
        "if os.path.exists(\"/content/drive/MyDrive/Models/horse2zebra/disc_Z.index\"):\r\n",
        "  print(\"loaded weigths for disc_Z\")\r\n",
        "  disc_Z.load_weights(\"/content/drive/MyDrive/Models/horse2zebra/disc_Z\")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIJixgLJ1aza"
      },
      "source": [
        "#  CALLBACKS\r\n",
        "\r\n",
        "def change_lr(optimizer): \r\n",
        "    new_lr = optimizer.lr / 1.001\r\n",
        "    tf.keras.backend.set_value(optimizer.lr,new_lr)\r\n",
        "    \r\n",
        "def earlyStopping(loss_list, min_delta=0.1, patience=8):\r\n",
        "    #No early stopping for 2*patience epochs \r\n",
        "    if len(loss_list)//patience < 2 :\r\n",
        "        return False\r\n",
        "    treshold = loss_list[-patience]\r\n",
        "    for l in loss_list[-patience:]:\r\n",
        "      if l <= treshold - min_delta:\r\n",
        "        return False\r\n",
        "    return True\r\n",
        " \r\n",
        "def save_best_weights(model, loss_list, model_path):\r\n",
        "    '''\r\n",
        "    Saves the model weights, if the loss for the current run was the lowest.\r\n",
        "      Parameters:\r\n",
        "        model: The model you want to save the weights for.\r\n",
        "        loss_list: The list of the losses of the above model.\r\n",
        "        model_path: string appended to the end of the path where the model is gonna be saved.\r\n",
        "    '''\r\n",
        "    if loss_list[-1] != min(loss_list):\r\n",
        "      return\r\n",
        "\r\n",
        "\r\n",
        "    checkpoint_path = \"/content/drive/MyDrive/Models/horse2zebra\"\r\n",
        "    cp_path = os.path.join(checkpoint_path, model_path)\r\n",
        "    model.save_weights(cp_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEhUe3zS5k_C"
      },
      "source": [
        "# Define the gradient functions\r\n",
        "\r\n",
        "@tf.function\r\n",
        "def get_gen_loss_and_grads(real_H, real_Z):\r\n",
        "  '''\r\n",
        "  Returns the loss and gradients for both generators and the generated\r\n",
        "  fake images of class H and Z for the discriminator loss.\r\n",
        "      Parameters:\r\n",
        "        real_H: real examples of class H\r\n",
        "        real_Z: real examples of class Z\r\n",
        "      Returns: (gen_loss, grads_HZ, grads_ZH, fake_H, fake_Z)\r\n",
        "  '''\r\n",
        "  with tf.GradientTape() as tape_HZ, tf.GradientTape() as tape_ZH:\r\n",
        "    gen_loss, fake_H, fake_Z = get_generator_loss(real_A= real_H, real_B= real_Z, gen_AB= gen_HZ, gen_BA= gen_ZH,\r\n",
        "                                  disc_A= disc_H, disc_B= disc_Z, adv_critereon= adv_critereon, \r\n",
        "                                  identity_critereon= identity_critereon, cycle_critereon= cycle_critereon)\r\n",
        "    \r\n",
        "  grads_HZ = tape_HZ.gradient(gen_loss, gen_HZ.trainable_variables)\r\n",
        "  grads_ZH = tape_ZH.gradient(gen_loss, gen_ZH.trainable_variables)\r\n",
        "  return gen_loss, grads_HZ, grads_ZH, fake_H, fake_Z\r\n",
        "\r\n",
        "\r\n",
        "@tf.function\r\n",
        "def get_disc_loss_and_grads(real_H, real_Z, fake_H, fake_Z):\r\n",
        "  '''\r\n",
        "  Returns the loss and gradients for both discriminators.\r\n",
        "      Parameters:\r\n",
        "        real_H: real examples of class H\r\n",
        "        real_Z: real examples of class Z\r\n",
        "        real_H: generated images of class H\r\n",
        "        real_Z: generated images of class Z\r\n",
        "        Returns: (disc_loss, grads_H, grads_Z)\r\n",
        "  '''\r\n",
        "  with tf.GradientTape() as tape_H, tf.GradientTape() as tape_Z:\r\n",
        "    disc_loss_H = get_disc_loss(real_H, fake_H, disc_H, adv_critereon)\r\n",
        "    disc_loss_Z = get_disc_loss(real_Z, fake_Z, disc_Z, adv_critereon)\r\n",
        "\r\n",
        "    grads_H = tape_H.gradient(disc_loss_H, disc_H.trainable_variables)\r\n",
        "    grads_Z = tape_Z.gradient(disc_loss_Z, disc_Z.trainable_variables)\r\n",
        "\r\n",
        "    disc_loss = (disc_loss_H + disc_loss_Z)/2\r\n",
        "\r\n",
        "  return disc_loss, grads_H, grads_Z\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHd5AKuxPAIK"
      },
      "source": [
        "# Training the network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp_bSFiXMuZ5"
      },
      "source": [
        "datagen_H, datagen_Z = get_train_generators(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An8jXpeBYkpI"
      },
      "source": [
        " !pip install colorama\n",
        " \n",
        "import time\n",
        "# from tqdm import tqdm, \n",
        "from tqdm.notebook import tqdm\n",
        "from colorama import Fore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvU9zg7dzSHC"
      },
      "source": [
        "epochs = 10\n",
        " \n",
        "epoch_gen_losses = []\n",
        "epoch_disc_losses = []\n",
        "mean_epoch_gen_loss = 0\n",
        "mean_epoch_disc_loss = 0\n",
        " \n",
        "fake_H_imgs = []\n",
        "fake_Z_imgs = []\n",
        "temp_gen_losses = []\n",
        "temp_disc_losses = []\n",
        " \n",
        "print(\"Training started!\")\n",
        "for epoch in range(epochs):\n",
        "  mean_batch_gen_loss = 0\n",
        "  mean_batch_disc_loss = 0\n",
        "  \n",
        "  print(\"Epoch number \"+ str(epoch))\n",
        " \n",
        "  start_time = time.time()\n",
        "  for i, (real_H, real_Z) in tqdm(enumerate(zip(datagen_H, datagen_Z)), total=len(datagen_Z), bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % (Fore.BLUE, Fore.RESET)):\n",
        " \n",
        "    # Get the loss and gradient values from the generator\n",
        "    gen_loss, grads_HZ, grads_ZH, fake_H, fake_Z = get_gen_loss_and_grads(real_H, real_Z)\n",
        "      \n",
        "    # Apply the gradients to the generators\n",
        "    gen_optim.apply_gradients(zip(grads_HZ, gen_HZ.trainable_variables))\n",
        "    gen_optim.apply_gradients(zip(grads_HZ, gen_HZ.trainable_variables))\n",
        " \n",
        "    # Get the loss and gradient values from the discriminator\n",
        "    disc_loss, grads_H, grads_Z = get_disc_loss_and_grads(real_H, real_Z, fake_H, fake_Z)\n",
        " \n",
        "    # Apply the gradients to the discriminator\n",
        "    disc_optim.apply_gradients(zip(grads_H, disc_H.trainable_variables))\n",
        "    disc_optim.apply_gradients(zip(grads_Z, disc_Z.trainable_variables))\n",
        " \n",
        "    # Append some fake images to see progress \n",
        "    if i % 100 == 0:\n",
        "      temp_gen_losses.append(gen_loss)\n",
        "      temp_disc_losses.append(disc_loss)\n",
        "    if i % 250 == 0:\n",
        "      fake_H_imgs.append(fake_H)\n",
        "      fake_Z_imgs.append(fake_Z)     \n",
        "      print(\"i = \" + str(i) + \":  gen loss = \" + str(gen_loss))\n",
        "      print(\"i = \" + str(i) + \":  disc loss = \" + str(disc_loss))\n",
        " \n",
        "    # Save the losses for the current batch\n",
        "    mean_batch_gen_loss += gen_loss.numpy()/len(datagen_Z)\n",
        "    mean_batch_disc_loss += disc_loss.numpy()/len(datagen_Z)\n",
        " \n",
        "    # Stop this epoch after one run through the generator\n",
        "    if (i == len(datagen_Z)):\n",
        "      break\n",
        " \n",
        "      \n",
        " \n",
        "  # == End of the first loop =============================\n",
        " \n",
        "  # Save the losses for the current epoch\n",
        "  epoch_gen_losses.append(mean_batch_gen_loss)\n",
        "  mean_epoch_gen_loss += mean_batch_gen_loss/epochs\n",
        " \n",
        "  epoch_disc_losses.append(mean_batch_disc_loss)\n",
        "  mean_epoch_disc_loss += mean_batch_disc_loss/epochs\n",
        " \n",
        "  # Update the learning rate\n",
        "  change_lr(gen_optim)\n",
        "  change_lr(disc_optim)\n",
        " \n",
        "  # Check for early stopping on the generator\n",
        "  if earlyStopping(epoch_gen_losses):\n",
        "    break\n",
        " \n",
        "  # Save the model weights if needed\n",
        "  save_best_weights(gen_HZ, epoch_gen_losses, \"gen_HZ\")\n",
        "  save_best_weights(gen_ZH, epoch_gen_losses, \"gen_ZH\")\n",
        " \n",
        "  save_best_weights(disc_H, epoch_disc_losses, \"disc_H\")\n",
        "  save_best_weights(disc_Z, epoch_disc_losses, \"disc_Z\")\n",
        " \n",
        "  end_time = time.time()\n",
        "  print(\"time: \" + str(end_time-start_time))\n",
        " \n",
        "  plt.plot(temp_gen_losses)\n",
        "  plt.ylabel(\"generator losses\")\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(temp_disc_losses)\n",
        "  plt.ylabel(\"Discriminator losses\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyFty0uvqq6_"
      },
      "source": [
        "plt.imshow(np.squeeze(fake_Z_imgs[15]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGPpm6PFuz8u"
      },
      "source": [
        "reals = next(datagen_H)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPEFlhxjugLJ"
      },
      "source": [
        "pred_fake = disc_H(fake_H_imgs[0])\r\n",
        "pred_real = disc_H(reals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wikqEpSpuNtz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}